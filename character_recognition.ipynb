{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character_recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtXtmaYJ4POF0U565YJDlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patricksabry1/42028-Deep-Learning/blob/master/character_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssLx4iFxm4uU",
        "colab_type": "text"
      },
      "source": [
        "# Character Recognition model Using OpenCV & deep CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjBX2noqmFSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f20812b-5734-4700-a69c-c467ba1a52e7"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxCZzObesycV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f5b3956-f947-450b-d17c-43799ea54f71"
      },
      "source": [
        "cd /content/gdrive/My Drive/42028-DL-CNN-2020/assignment-3/"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/42028-DL-CNN-2020/assignment-3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e7QJ8snsGWl",
        "colab_type": "text"
      },
      "source": [
        "# Pre-process cropped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfRpap22sGN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "# Apply canny edge detection \n",
        "def auto_canny(image, sigma=0.33):\n",
        "    v = np.median(image)\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    edged_image = cv.Canny(image, lower, upper)\n",
        " \n",
        "    return edged_image\n",
        "\n",
        "# Crops characters out of numerplate \n",
        "def crop_ctrs(img):\n",
        "    ret, mask = cv2.threshold(grayimage, 254, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    cv2.imshow('mask', mask)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    image, contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, \n",
        "    cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "\n",
        "        if cv2.contourArea(contour) < 200:\n",
        "            continue\n",
        "\n",
        "        rect = cv2.minAreaRect(contour)\n",
        "        box = cv2.boxPoints(rect)\n",
        "\n",
        "        ext_left = tuple(contour[contour[:, :, 0].argmin()][0])\n",
        "        ext_right = tuple(contour[contour[:, :, 0].argmax()][0])\n",
        "        ext_top = tuple(contour[contour[:, :, 1].argmin()][0])\n",
        "        ext_bot = tuple(contour[contour[:, :, 1].argmax()][0])\n",
        "\n",
        "        roi_corners = np.array([box], dtype=np.int32)\n",
        "\n",
        "        cv2.polylines(bounding_box_image, roi_corners, 1, (255, 0, 0), 3)\n",
        "        cv2.imshow('image', bounding_box_image)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "        cropped_image = grayimage[ext_top[1]:ext_bot[1], ext_left[0]:ext_right[0]]\n",
        "        cv2.imwrite('crop.jpg', cropped_image)\n",
        "\n",
        "path = \"/content/gdrive/My Drive/42028-DL-CNN-2020/assignment-3/cropped_dataset/plates/train/\"\n",
        "bounding_boxes = []\n",
        "for image_path in os.listdir(path):\n",
        "    full_image_path = os.path.join(path, image_path)\n",
        "    img = cv.imread(full_image_path)\n",
        "\n",
        "    # Loop through each image, apply pre-processing & localize onto each character\n",
        "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    thresh_inv = cv.adaptiveThreshold(gray,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY_INV,39,1)\n",
        "    edges = auto_canny(thresh_inv)\n",
        "    ctrs, _ = cv.findContours(edges.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv.boundingRect(ctr)[0])\n",
        "\n",
        "    img_area = img.shape[0]*img.shape[1]\n",
        "\n",
        "    # Get bounding box co-ordinates for image cropping\n",
        "    for i, ctr in enumerate(sorted_ctrs):\n",
        "        x, y, w, h = cv.boundingRect(ctr)\n",
        "        roi_area = w*h\n",
        "        roi_ratio = roi_area/img_area\n",
        "\n",
        "        if((roi_ratio >= 0.04) and (roi_ratio < 0.18)):\n",
        "                if ((h>1.2*w) and (3*w>=h)):\n",
        "                    cv.rectangle(img,(x,y),( x + w, y + h ),(90,0,255), 1)\n",
        "                    bounding_boxes.append((x,y,w,h))\n",
        "\n",
        "# Crop bounding boxes and save into new dir\n",
        "count = 0\n",
        "for box in bounding_boxes:\n",
        "    x,y,w,h = box\n",
        "    ROI = img[y:y+h, x:x+w]\n",
        "    cv.imwrite('/content/gdrive/My Drive/42028-DL-CNN-2020/assignment-3/cropped_dataset/characters/train/char_{}.png'.format(str(count)), ROI)\n",
        "    count += 1\n",
        "    cv2_imshow(ROI)\n",
        "    cv.waitKey()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VorxjpD09o8i",
        "colab_type": "text"
      },
      "source": [
        "# Deep CNN for character image classification\n",
        "\n",
        "The localized numberplate characters are cropped and used as input data for an image classification CNN model which will have 35 target classes (all alphanumericals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8CWD4ZD2fIV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}